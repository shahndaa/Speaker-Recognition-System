{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ec9b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               10496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,037\n",
      "Trainable params: 44,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "188/188 [==============================] - 3s 8ms/step - loss: 0.2514 - accuracy: 0.9243 - val_loss: 0.0250 - val_accuracy: 0.9960\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.0103 - val_accuracy: 0.9973\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0121 - val_accuracy: 0.9960\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0061 - val_accuracy: 0.9973\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0102 - val_accuracy: 0.9967\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0121 - val_accuracy: 0.9973\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 6.0431e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 8.6389e-04 - accuracy: 0.9997 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 8.5266e-04 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 8.5651e-04 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 7.8143e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 4.0981e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 9.4663e-04 - accuracy: 0.9995 - val_loss: 2.2785e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 6.7241e-04 - val_accuracy: 0.9993\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 4.3358e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 9.6840e-04 - val_accuracy: 0.9993\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 4.2562e-04 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 3.6183e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 6.1767e-04 - accuracy: 0.9997 - val_loss: 0.0023 - val_accuracy: 0.9987\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 8.5182e-04 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.9551e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0022 - val_accuracy: 0.9987\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9987\n",
      "Test Accuracy: 99.87%\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "Predicted Speaker: Nelson_Mandela\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load Audio Data\n",
    "def load_audio_data(dataset_path):\n",
    "    features, labels = [], []\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                # Load audio file\n",
    "                audio, sr = librosa.load(file_path, sr=22050)\n",
    "                # Extract MFCC features\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "                mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "                features.append(mfccs_mean)\n",
    "                labels.append(folder)  # Folder name as label\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "\n",
    "# Step 2: Preprocess Data\n",
    "def preprocess_data(features, labels):\n",
    "    le = LabelEncoder()\n",
    "    labels_encoded = le.fit_transform(labels)\n",
    "    labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "    # Fit scaler on the training features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    return train_test_split(features_scaled, labels_categorical, test_size=0.2, random_state=42), le, scaler\n",
    "\n",
    "# Step 3: Build Model\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"C:/Users/LENOVO/Speech Processing/Speech Project/Datasets\"  # Replace with the dataset path\n",
    "    features, labels = load_audio_data(dataset_path)\n",
    "\n",
    "    # Check if features are empty\n",
    "    if len(features) == 0:\n",
    "        raise ValueError(\"No valid audio files were processed.\")\n",
    "\n",
    "    # Preprocess the data\n",
    "    (X_train, X_test, y_train, y_test), label_encoder, scaler = preprocess_data(features, labels)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_model(X_train.shape[1], y_train.shape[1])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"speaker_identification_model.h5\")\n",
    "\n",
    "    # Decode predictions\n",
    "    def predict_speaker(audio_path, model, label_encoder, scaler):\n",
    "      audio, sr = librosa.load(audio_path, sr=22050)\n",
    "      mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "      mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "      mfccs_scaled = scaler.transform([mfccs_mean]) # Transform using the fitted scaler\n",
    "      prediction = model.predict(mfccs_scaled) # Predict speaker\n",
    "      speaker = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "      return speaker[0]\n",
    "\n",
    "\n",
    "    # Test Prediction\n",
    "    test_audio_path = \"C:/Users/LENOVO/Speech Processing/Speech Project/16000_pcm_speeches/test/1499.wav\"  # Replace with a test audio file path\n",
    "    print(f\"Predicted Speaker: {predict_speaker(test_audio_path, model, label_encoder, scaler)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
